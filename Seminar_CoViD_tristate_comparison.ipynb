{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science 2 Seminar paper\n",
    "## Business/project evaluation stage\n",
    "\n",
    "### Premise\n",
    "What is the effect of personal travel on CoViD-19 infection rates in the tri-state area?\n",
    "As some of the possible factors I will look into:\n",
    "- open vs closed borders  \n",
    "- open vs closed stores \n",
    "- vacation times\n",
    "\n",
    "Since border traffic was never entirely shut down for business traffic i.e. commuters we won't look into that. \n",
    "\n",
    "The hypothesis is that all 3 factores have an impact on infection rates. If that can be shown, I will try to form a prediction model for future holidays.\n",
    "\n",
    "### Preliminary plan of action\n",
    "* Define area of relevance based on travel/shopping/commute\n",
    "* Evaluate infection response/delay windows to apply to infection timelines\n",
    "* Construct an infection spike timeline for border region. \n",
    "  * Combined and statebased.\n",
    "  * Classify days as rising infection/not\n",
    "* Construct independent/combined timelines for borders' state, stores' state and vacation times. \n",
    "* Test correlation to CoViD-19 statistics in the involved countries/overall\n",
    "* Classify spike events as border/store/vacation\n",
    "* See if a prediction can be made\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt, timedelta\n",
    "\n",
    "from utility.helpers import *\n",
    "import utility.init as util\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slowe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emr_df = pd.read_csv(util.emr_infection_data)\n",
    "de_ref_df = pd.read_csv(util.de_reference_data)\n",
    "nl_ref_df = pd.read_csv(util.nl_reference_data)\n",
    "be_ref_df = pd.read_csv(util.be_reference_data)\n",
    "\n",
    "# add date typ columns\n",
    "emr_df = addDateTypeColumn(emr_df,'XDate')\n",
    "de_ref_df = addDateTypeColumn(de_ref_df,'XDate')\n",
    "nl_ref_df = addDateTypeColumn(nl_ref_df,'XDate')\n",
    "be_ref_df = addDateTypeColumn(be_ref_df,'XDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lastRowsValue(window):\n",
    "    return window[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDRC_SL_Yesterday</th>\n",
       "      <th>N_Day_Rate_Change_Sliding_Window</th>\n",
       "      <th>Date</th>\n",
       "      <th>OffDayFactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.093183</td>\n",
       "      <td>1.075902</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.075902</td>\n",
       "      <td>1.074059</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.074059</td>\n",
       "      <td>1.067411</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.067411</td>\n",
       "      <td>1.071119</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.071119</td>\n",
       "      <td>1.041553</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>1.370667</td>\n",
       "      <td>1.361200</td>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>1.361200</td>\n",
       "      <td>1.435401</td>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1.435401</td>\n",
       "      <td>1.528716</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>1.528716</td>\n",
       "      <td>1.551841</td>\n",
       "      <td>2021-11-14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>1.551841</td>\n",
       "      <td>1.181258</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>599 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NDRC_SL_Yesterday  N_Day_Rate_Change_Sliding_Window        Date  \\\n",
       "9             1.093183                          1.075902  2020-03-24   \n",
       "10            1.075902                          1.074059  2020-03-25   \n",
       "11            1.074059                          1.067411  2020-03-26   \n",
       "12            1.067411                          1.071119  2020-03-27   \n",
       "13            1.071119                          1.041553  2020-03-28   \n",
       "..                 ...                               ...         ...   \n",
       "603           1.370667                          1.361200  2021-11-11   \n",
       "604           1.361200                          1.435401  2021-11-12   \n",
       "605           1.435401                          1.528716  2021-11-13   \n",
       "606           1.528716                          1.551841  2021-11-14   \n",
       "607           1.551841                          1.181258  2021-11-15   \n",
       "\n",
       "     OffDayFactor  \n",
       "9            10.0  \n",
       "10           11.0  \n",
       "11           12.0  \n",
       "12           13.0  \n",
       "13           14.0  \n",
       "..            ...  \n",
       "603           3.0  \n",
       "604           3.0  \n",
       "605           2.0  \n",
       "606           1.0  \n",
       "607           0.0  \n",
       "\n",
       "[599 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtr_df = emr_df.loc[emr_df.Province_Id == 30]\n",
    "\n",
    "gbtr_df = pd.merge(gbtr_df, de_ref_df, on='Date', how='outer')\n",
    "gbtr_df['NDRC_SL_Yesterday'] = gbtr_df['N_Day_Rate_Change_Sliding_Window'].rolling(2, min_periods=1).apply(lastRowsValue, raw=True )\n",
    "\n",
    "gbtr_df = gbtr_df.loc[gbtr_df.NDRC_SL_Yesterday.notna() & gbtr_df.N_Day_Rate_Change_Sliding_Window.notna() ,['NDRC_SL_Yesterday','N_Day_Rate_Change_Sliding_Window','Date','OffDayFactor']]\n",
    "gbtr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4462742951798032"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = gbtr_df.loc[:,['Date','NDRC_SL_Yesterday','OffDayFactor']]\n",
    "y = gbtr_df.N_Day_Rate_Change_Sliding_Window\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "gbtReg = GradientBoostingRegressor(max_depth = 2, subsample = 0.1, n_estimators = 50, learning_rate= 0.05, loss='lad', random_state=0)\n",
    "\n",
    "gbtReg.fit(X_train, y_train)\n",
    "gbtReg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -0.068 (0.010)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold, StratifiedKFold\n",
    "\n",
    "gbtRegModel = GradientBoostingRegressor(max_depth = 2, subsample = 0.1, n_estimators = 50, learning_rate= 0.05, loss='lad',random_state=1)\n",
    "crossVal = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(gbtRegModel, X, y, scoring='neg_mean_absolute_error' , cv=crossVal, n_jobs=-1, error_score='raise') # , scoring='neg_mean_absolute_error'\n",
    "\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 60 folds for each of 3 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedKFold(n_repeats=3, n_splits=20, random_state=1),\n",
       "             estimator=GradientBoostingRegressor(loss='lad', random_state=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.05], 'max_depth': [2, 3, 4],\n",
       "                         'n_estimators': [50], 'subsample': [0.1]},\n",
       "             scoring='neg_mean_absolute_error', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [2],\n",
    "    # 'max_features': [2, 3],\n",
    "    'subsample'    : [0.1],\n",
    "    # 'min_samples_leaf': [3, 4, 5],\n",
    "    # 'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [50],\n",
    "    'learning_rate': [0.05]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(loss='lad', random_state=1)\n",
    "cv = RepeatedKFold(n_splits=20, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator = gbr, param_grid = param_grid, \n",
    "                          cv = cv, n_jobs = -1, verbose = 2, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.05, loss='lad', max_depth=2,\n",
      "                          n_estimators=50, random_state=1, subsample=0.1)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " -0.06766992741685841\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_search.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_search.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4549932891636499"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = gbtr_df.loc[:,['NDRC_SL_Yesterday','OffDayFactor']]\n",
    "y = gbtr_df.N_Day_Rate_Change_Sliding_Window\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.4, random_state=1)\n",
    "\n",
    "gbtReg = KernelRidge()\n",
    "gbtReg.fit(X_train, y_train)\n",
    "gbtReg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3796438105215253"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "regr = make_pipeline(StandardScaler(), SVR(kernel='rbf',C=1.0, epsilon=0.2))\n",
    "regr.fit(X_train, y_train)\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6986a36ff9abca86503c5bd35118269cd53a990e839cd5391635b68506b8c830"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('Lab1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
