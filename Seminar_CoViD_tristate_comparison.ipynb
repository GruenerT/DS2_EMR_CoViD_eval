{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science 2 Seminar\n",
    "## Business/project evaluation stage\n",
    "\n",
    "### Premise\n",
    "Vacations/holidays have a visible effect on CoViD-19 infection rates in the tri-state area.\n",
    "\n",
    "If that can be shown, I will try to form a prediction model for future holidays.\n",
    "\n",
    "### Evaluation \n",
    "* The area of relevance is the EMR (Euregio Maas-Rhine region) as defined by the EU\n",
    "  * The CoViD-19 data corresponding to that area is collected and transformed into a unified format in \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt, timedelta\n",
    "\n",
    "from helpers import *\n",
    "import init as util\n",
    "\n",
    "from dataprep import  *\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slowe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation stage\n",
    "### Generating data\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emr_df = prepareData(save=True)\n",
    "# be_ref_df, nl_ref_df, de_ref_df = prepareRefCals(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing previously prepared data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emr_df = pd.read_csv(util.emr_infection_data)\n",
    "emr_df = addDateTypeColumn(emr_df,'Date')\n",
    "\n",
    "be_ref_df, nl_ref_df, de_ref_df = loadRefData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDf(base_df, provinceId, mergeDf=None):\n",
    "    loc_df = base_df.copy()\n",
    "    loc_df = loc_df.loc[loc_df.Province_Id == provinceId]\n",
    "    loc_df = loc_df.rename(columns={'N_Day_Rate_Change_Sliding_Window':'NDRC_SW'})\n",
    "    loc_df['NDRC_SW_Yesterday'] = loc_df['NDRC_SW'].rolling(2, min_periods=1).apply(lambda x: x[0], raw=True )\n",
    "    loc_df = loc_df.loc[loc_df.NDRC_SW_Yesterday.notna() & loc_df.NDRC_SW.notna() ,['NDRC_SW_Yesterday','NDRC_SW','Date']]\n",
    "    if mergeDf is not None:\n",
    "        loc_df = pd.merge(loc_df, mergeDf.loc[:,['Date','OffDayFactor']], on='Date', how='left')\n",
    "\n",
    "    loc_df = loc_df.set_index('Date')\n",
    "    loc_df = loc_df.asfreq('D')\n",
    "    loc_df = loc_df.sort_index()\n",
    "\n",
    "    return loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_off_dfs = {}\n",
    "nl_off_dfs = {}\n",
    "be_off_dfs = {}\n",
    "\n",
    "for i in [10,20,30,40]:\n",
    "    de_off_dfs[i] = prepareDf(emr_df, i, de_ref_df)\n",
    "\n",
    "for i in [10,20,30,40]:\n",
    "    nl_off_dfs[i] = prepareDf(emr_df, i, nl_ref_df)\n",
    "\n",
    "for i in [10,20,30,40]:\n",
    "    be_off_dfs[i] = prepareDf(emr_df, i, be_ref_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify interval completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Off days: be provinceId: 10 complete: True\n",
      "Off days: be provinceId: 20 complete: True\n",
      "Off days: be provinceId: 30 complete: True\n",
      "Off days: be provinceId: 40 complete: True\n",
      "Off days: nl provinceId: 10 complete: True\n",
      "Off days: nl provinceId: 20 complete: True\n",
      "Off days: nl provinceId: 30 complete: True\n",
      "Off days: nl provinceId: 40 complete: True\n",
      "Off days: de provinceId: 10 complete: True\n",
      "Off days: de provinceId: 20 complete: True\n",
      "Off days: de provinceId: 30 complete: True\n",
      "Off days: de provinceId: 40 complete: True\n"
     ]
    }
   ],
   "source": [
    "for name, df_dict in [('be',be_off_dfs), ('nl',nl_off_dfs), ('de',de_off_dfs)]:\n",
    "    for k, df in df_dict.items():\n",
    "        print('Off days: {od} provinceId: {pid} complete: {comp}'.format(od=name, pid =k, comp=(df.index == pd.date_range(start=df.index.min(),\n",
    "                                    end=df.index.max(),\n",
    "                                    freq=df.index.freq)).all()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "RR yields similar results concerning errors as Gradient Boosting did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7507837357015851"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pt_gbtr_df = de_off_dfs[30].copy()\n",
    "X, y = pt_gbtr_df.loc[:,['NDRC_SW_Yesterday','OffDayFactor']], pt_gbtr_df.NDRC_SW\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "gbtReg = KernelRidge()\n",
    "gbtReg.fit(X_train, y_train)\n",
    "gbtReg.score(X_test, y_test) # R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "SVM yielded significantly worse results compared to both RR and Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9620752470085565"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtr_df = de_off_dfs[30].copy()\n",
    "X, y = gbtr_df.loc[:,['NDRC_SW_Yesterday','OffDayFactor']], gbtr_df.NDRC_SW\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=1)\n",
    "\n",
    "regr = make_pipeline(StandardScaler(), SVR(kernel='rbf',C=1.0, epsilon=0.2))\n",
    "regr.fit(X_train, y_train)\n",
    "regr.score(X_test, y_test) # R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7580852628307823"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_gbtr_df = de_off_dfs[30].copy()\n",
    "X, y = pt_gbtr_df.loc[:,['NDRC_SW_Yesterday','OffDayFactor']], pt_gbtr_df.NDRC_SW\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# From Gridsearch\n",
    "params = {'learning_rate': 0.075,\n",
    " 'max_depth': 3,\n",
    " 'min_samples_leaf': 10,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 80,\n",
    " 'subsample': 0.85\n",
    " }\n",
    "\n",
    "gbtReg = GradientBoostingRegressor( random_state=0, **params)\n",
    "\n",
    "gbtReg.fit(X_train, y_train)\n",
    "gbtReg.score(X_test, y_test) # R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "The original grid params are commented out to have it run in reasonable time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'max_depth': [2, 3, 5, 10],\n",
    "#     'subsample': [0.05, 0.1, 0.2, 0.5, 0.8, 0.85, 0.9],\n",
    "#     'n_estimators': [10, 50, 80, 90, 100, 200, 500],\n",
    "#     'learning_rate': [0.01, 0.02, 0.05,0.075, 0.1, 0.5],\n",
    "# 'min_samples_split': [2, 5, 10],\n",
    "# 'min_samples_leaf': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3],\n",
    "    'subsample': [0.85],\n",
    "    'n_estimators': [80, 90, 100],\n",
    "    'learning_rate': [0.075],\n",
    "    'min_samples_split':[2],\n",
    "    'min_samples_leaf':[10]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(criterion='mae', loss='lad', random_state=1)\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator = gbr, param_grid = param_grid, \n",
    "                          cv = cv, n_jobs = -1, verbose = 0, scoring='neg_mean_absolute_error')\n",
    "results = pd.DataFrame(columns={'region','offdays','score'})\n",
    "\n",
    "for name, df_dict in [('be',be_off_dfs), ('nl',nl_off_dfs), ('de',de_off_dfs)]:\n",
    "    for k, df in df_dict.items():\n",
    "        X = df.loc[:,['NDRC_SW_Yesterday','OffDayFactor']]\n",
    "        y = df.NDRC_SW\n",
    "        grid_search.fit(X, y)\n",
    "        res = grid_search.best_params_.copy()\n",
    "        res['offdays'] = name\n",
    "        res['region'] = k\n",
    "        res['score'] = grid_search.best_score_\n",
    "        results = results.append(res, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting scores show that on very similar parameters the predictions across borders and across the whole EMR are roughly equally as well as the ones of off-days corresponding to their own country.\n",
    "The scores as such seem to be in a range where they give predictions in the right ball park but aren't suitable for forecasts over longer stretches.\n",
    "This stems from each prediction being based on a true value of the previous day.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "fk_df = de_off_dfs[30].copy()\n",
    "\n",
    "test_range = 17\n",
    "data_train = fk_df[:-test_range]\n",
    "data_test = fk_df[-test_range:]\n",
    "\n",
    "regr = GradientBoostingRegressor(criterion='mae',loss='lad', random_state=1, **params)\n",
    "forecaster = ForecasterAutoreg( regressor = regr, lags = 100 )\n",
    "# forecaster.fit(y=data_train.NDRC_SW, exog=data_train.loc[:,['NDRC_SW_Yesterday','OffDayFactor']])\n",
    "forecaster.fit(y=data_train.NDRC_SW, exog=data_train.loc[:,['OffDayFactor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = forecaster.predict(steps=test_range, exog=data_test.loc[:,['NDRC_SW_Yesterday','OffDayFactor']])\n",
    "predictions = forecaster.predict(steps=test_range, exog=data_test.loc[:,['OffDayFactor']])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "data_train.NDRC_SW.plot(ax=ax, label='train')\n",
    "data_test.NDRC_SW.plot(ax=ax, label='test')\n",
    "predictions.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_fk_df = de_off_dfs[30].copy()\n",
    "\n",
    "window = 17\n",
    "train, test = rec_fk_df[:-window] , rec_fk_df[-window:]\n",
    "\n",
    "predictions = test.copy()\n",
    "predictions.NDRC_SW = np.NAN\n",
    "predictions.loc[1:, 'NDRC_SW_Yesterday'] = np.NAN\n",
    "\n",
    "X_train, y_train = train.loc[:,['NDRC_SW_Yesterday','OffDayFactor']], train.loc[:,'NDRC_SW']\n",
    "\n",
    "gbr = GradientBoostingRegressor( random_state=0, **params)\n",
    "\n",
    "# gbtReg.fit(X_train, y_train)\n",
    "# gbtReg.score(X_test, y_test) # R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "# rec_fk_df.NDRC_SW.plot(ax=ax, label='orig')\n",
    "train.NDRC_SW.plot(ax=ax, label='train')\n",
    "test.NDRC_SW.plot(ax=ax, label='test')\n",
    "# predictions.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6986a36ff9abca86503c5bd35118269cd53a990e839cd5391635b68506b8c830"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('Lab1': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
